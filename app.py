"""
ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆLPåˆ†æã‚¢ãƒ—ãƒª
ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§è¦–è¦šçš„ãªæ”¹å–„ç‚¹ã‚’åˆ†æ
"""
import os
import base64
import streamlit as st

from src.capture.simple_capture import fetch_page
from src.llm.exceptions import StructuredCallError
from src.llm.pipeline import run_structured_pipeline
from src.utils.io import make_run_dir, read_text
from src.utils.run_logger import RunLogger
from src.llm.genre_prompts import GENRES, get_genre_system_prompt, get_genre_analysis_prompt_addition, get_genre_specific_rules

st.set_page_config(page_title="LP AI Analyzer", layout="wide")
st.title("ğŸ¨ AI-Powered Landing Page Analyzer")
st.caption("ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã«æœ€é©åŒ–ã•ã‚ŒãŸè¦–è¦šæ”¹å–„ã®ææ¡ˆ")

# ä½¿ã„æ–¹ã®ã‚¬ã‚¤ãƒ‰
with st.expander("ğŸ“– ä½¿ã„æ–¹", expanded=False):
    st.markdown("""
    ### ğŸ“ 3ã‚¹ãƒ†ãƒƒãƒ—ã§ç°¡å˜åˆ†æ
    
    **Step 1: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§è¨­å®š**
    - â† å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒLPã®ç¨®é¡ã€ã‚’é¸æŠ
    - SaaS / D2C / æ•™è‚² / æ¡ç”¨ / ã‚¢ãƒ—ãƒª ã‹ã‚‰é¸æŠ
    
    **Step 2: URLã‚’å…¥åŠ›**
    - åˆ†æã—ãŸã„LPã®URLã‚’å…¥åŠ›
    
    **Step 3: è§£æå®Ÿè¡Œ**
    - ã€ŒğŸš€ è§£æã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    - é¸æŠã—ãŸã‚¸ãƒ£ãƒ³ãƒ«ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åˆ†æã•ã‚Œã¾ã™
    """)

# ==== Sidebar: Settings ====
st.sidebar.header("âš™ï¸ è¨­å®š")

st.sidebar.markdown("### ğŸ“Œ Step 1: LPã®ç¨®é¡ã‚’é¸æŠ")
st.sidebar.caption("ğŸ‘‡ ã¾ãšã¯ã“ã¡ã‚‰ã‚’é¸æŠã—ã¦ãã ã•ã„")

# ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ
genre = st.sidebar.selectbox(
    "LPã®ç¨®é¡",
    options=list(GENRES.keys()),
    format_func=lambda x: GENRES[x],
    help="LPã®ç¨®é¡ã«å¿œã˜ã¦æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½¿ç”¨ã•ã‚Œã¾ã™"
)

st.sidebar.success(f"âœ… é¸æŠä¸­: **{GENRES[genre]}**")
st.sidebar.markdown("---")

model_vendor = st.sidebar.selectbox(
    "Model vendor", ["Google Gemini", "OpenAI"]
)

if model_vendor == "Google Gemini":
    model_name = st.sidebar.selectbox(
        "Gemini model", 
        ["gemini-2.5-flash", "gemini-2.5-pro"],
        help="""
        Flash: é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãƒ»æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ãªã—ï¼ˆæ¨å¥¨ï¼‰
        Pro: é«˜å“è³ªã ãŒæ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ã§é…ãã€ã‚³ã‚¹ãƒˆãŒé«˜ã„
        
        â„¹ï¸ é¸æŠã—ãŸmodelãŒåˆ†æã«ä½¿ç”¨ã•ã‚Œã¾ã™
        """
    )
else:
    model_name = st.sidebar.selectbox(
        "OpenAI model", 
        ["gpt-5", "gpt-5-mini", "gpt-5-nano"],
        index=0,
        help="""
        gpt-5: æœ€é«˜å“è³ªï¼ˆè¤‡é›‘ãªæ¨è«–ãƒ»ã‚³ãƒ¼ãƒ‰ç”Ÿæˆï¼‰
        gpt-5-mini: ã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
        gpt-5-nano: é«˜é€Ÿå‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ï¼‰
        
        â„¹ï¸ é¸æŠã—ãŸmodelãŒåˆ†æã«ä½¿ç”¨ã•ã‚Œã¾ã™
        """
    )

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°è¨­å®šï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰
with st.sidebar.expander("ğŸ”§ è©³ç´°è¨­å®šï¼ˆä»»æ„ï¼‰", expanded=False):
    if model_vendor == "Google Gemini":
        st.caption("âš ï¸ Geminiã§ã¯ã€ã“ã‚Œã‚‰ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã•ã‚Œã‚‹æŒ‡ç¤ºæ–‡ã§ã™")
    else:
        st.caption("âœ… OpenAI GPT-5ã§ã¯ã€ã“ã‚Œã‚‰ã¯æ­£å¼ãªAPIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™")
    
    verbosity = st.selectbox(
        "å‡ºåŠ›ã®è©³ç´°åº¦ (Verbosity)", 
        ["low", "medium", "high"],
        index=0,
        help="""
        OpenAI GPT-5: æ­£å¼ãªAPIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (text.verbosity)
        - low: ç°¡æ½”ãªå‡ºåŠ›
        - medium: æ¨™æº–çš„ãªè©³ç´°åº¦
        - high: è©³ç´°ãªèª¬æ˜
        
        Gemini: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã¨ã—ã¦è¿½åŠ 
        """
    )
    effort = st.selectbox(
        "æ¨è«–ã®æ·±ã• (Reasoning Effort)", 
        ["minimal", "low", "medium", "high"],
        index=0,
        help="""
        OpenAI GPT-5: æ­£å¼ãªAPIãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (reasoning.effort)
        - minimal: æœ€é€Ÿï¼ˆæœ€å°é™ã®æ¨è«–ï¼‰
        - low: é«˜é€Ÿï¼ˆè»½ã„æ¨è«–ï¼‰
        - medium: æ¨™æº–ï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ï¼‰
        - high: æœ€é«˜å“è³ªï¼ˆæ·±ã„æ¨è«–ï¼‰
        
        Gemini: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã¨ã—ã¦è¿½åŠ 
        """
    )

extra_instruction = st.sidebar.text_area(
    "è¿½åŠ è¦æœ›ï¼ˆä»»æ„ï¼‰", 
    "",
    placeholder="ä¾‹ï¼‰ãƒ¢ãƒã‚¤ãƒ«ã§ã®è¦‹ã‚„ã™ã•ã‚’é‡è¦–"
)

# ==== Main: Input ====
st.markdown("---")
st.markdown(f"### ğŸ“ Step 2: URLå…¥åŠ›")
st.info(f"ğŸ’¡ ç¾åœ¨ã®è¨­å®š: **{GENRES[genre]}** å‘ã‘ã«æœ€é©åŒ–")
url = st.text_input("è§£æã™ã‚‹LPã®URL", placeholder="https://example.com/landing")

# ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®ã‚¬ã‚¤ãƒ‰è¡¨ç¤º
with st.expander(f"ğŸ’¡ {GENRES[genre]}ã®æ”¹å–„ãƒã‚¤ãƒ³ãƒˆï¼ˆå‚è€ƒï¼‰", expanded=False):
    st.markdown(get_genre_specific_rules(genre))

st.markdown("### ğŸš€ Step 3: è§£æå®Ÿè¡Œ")
run_btn = st.button("ğŸš€ è§£æã™ã‚‹", type="primary", use_container_width=True)

if run_btn and url:
    run_dir = make_run_dir(url)
    run_logger = RunLogger(run_dir, url=url)
    run_logger.set_context(
        model_vendor=model_vendor,
        model_name=model_name,
        genre=genre,
        verbosity=verbosity,
        effort=effort,
        extra_instruction=extra_instruction,
    )

    # ãƒšãƒ¼ã‚¸å–å¾—
    run_logger.add_step("fetch_page", "started", detail={"url": url})
    with st.status("ğŸ“¥ ãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­...", expanded=False) as s:
        try:
            art = fetch_page(url=url, run_dir=run_dir)
            s.update(label="âœ… å–å¾—å®Œäº†", state="complete")
        except Exception as e:
            s.update(label=f"âŒ å–å¾—å¤±æ•—: {e}", state="error")
            st.stop()
    
    run_logger.add_step("fetch_page", "success", detail={
        "html_path": art["html_path"],
        "css_paths": art.get("css_paths", []),
        "screenshot_paths": art.get("screenshot_paths", {}),
    })

    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆè¡¨ç¤º
    st.markdown("---")
    st.subheader("ğŸ“¸ å–å¾—ã—ãŸã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ")
    
    screenshot_paths = art.get("screenshot_paths", {})
    primary_screenshot = screenshot_paths.get("full") or screenshot_paths.get("viewport")
    
    if primary_screenshot and os.path.exists(primary_screenshot):
        st.image(primary_screenshot, caption="ãƒšãƒ¼ã‚¸å…¨ä½“", use_column_width=True)
    
    # HTMLã¨CSSã‚’å–å¾—
    html_source = art.get("html_text") or read_text(art["html_path"])
    css_bundle = art.get("external_css_text", "")
    
    # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    with open(primary_screenshot, "rb") as f:
        png_bytes = f.read()
    b64_png = base64.b64encode(png_bytes).decode()

    # LLMåˆ†æ
    st.markdown("---")
    st.subheader("ğŸ¤– AIåˆ†æä¸­...")
    
    # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
    genre_system_prompt = get_genre_system_prompt(genre)
    genre_addition = get_genre_analysis_prompt_addition(genre)
    
    # è¿½åŠ è¦æœ›ã‚’å«ã‚ã‚‹
    final_extra_instruction = f"{extra_instruction}\n\n{genre_addition}" if extra_instruction else genre_addition
    
    with st.spinner(f"{GENRES[genre]}ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åˆ†æä¸­..."):
        try:
            result, artifacts = run_structured_pipeline(
                html=html_source,
                css_bundle=css_bundle,
                image_b64=b64_png,
                image_bytes=png_bytes if model_vendor == "Google Gemini" else None,
                vendor=model_vendor,
                model=model_name,
                verbosity=verbosity,
                effort=effort,
                extra_instruction=final_extra_instruction,
                # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
                custom_system_prompt=genre_system_prompt,
            )
            
            run_logger.add_step("llm_pipeline", "success", detail={
                "vendor": model_vendor,
                "model": model_name,
                "genre": genre,
            })
            
        except StructuredCallError as exc:
            st.error("âŒ LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼")
            st.code(str(exc))
            run_logger.add_step("llm_pipeline", "error", detail={"error": str(exc)})
            st.stop()
        except Exception as exc:
            st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {exc}")
            run_logger.add_step("llm_pipeline", "error", detail={"error": str(exc)})
            st.stop()

    # åˆ†æçµæœã®è¡¨ç¤º
    st.markdown("---")
    st.success("âœ… åˆ†æå®Œäº†ï¼")
    
    # AnalysisResultã‹ã‚‰ç›´æ¥å–å¾—ã—ã¦è¾æ›¸å½¢å¼ã«å¤‰æ›
    issues = result.issues
    improvements = result.improvements
    
    # respã‚’æ‰‹å‹•ã§ä½œæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
    resp = {
        "issues": [issue.model_dump() for issue in issues],
        "improvements": [imp.model_dump() for imp in improvements],
    }
    
    # === å•é¡Œç‚¹ã®è¡¨ç¤º ===
    st.subheader("âš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œç‚¹")
    
    if not issues:
        st.info("å¤§ããªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        for idx, issue in enumerate(issues, 1):
            with st.expander(f"å•é¡Œ {idx}: {issue.title}", expanded=True):
                st.markdown(f"**èª¬æ˜**: {issue.detail}")
                if issue.evidence:
                    st.caption(f"ğŸ“Œ æ ¹æ‹ : {issue.evidence}")
                if issue.severity:
                    severity_color = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                    st.markdown(f"**é‡è¦åº¦**: {severity_color.get(issue.severity, 'ğŸŸ¡')} {issue.severity.upper()}")

    # === æ”¹å–„æ¡ˆã®è¡¨ç¤º ===
    st.markdown("---")
    st.subheader(f"ğŸ’¡ æ”¹å–„ææ¡ˆï¼ˆ{GENRES[genre]}å‘ã‘ï¼‰")
    
    if not improvements:
        st.info("æ”¹å–„ææ¡ˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.caption(f"ğŸ’¡ {len(improvements)}ä»¶ã®æ”¹å–„ææ¡ˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
        
        for idx, imp in enumerate(improvements, 1):
            with st.expander(f"æ”¹å–„ {idx}: {imp.title}", expanded=True):
                st.markdown(f"**ææ¡ˆå†…å®¹**: {imp.rationale}")
                
                # å¯¾è±¡ã¨ãªã‚‹å•é¡Œ
                if imp.targets_issue:
                    st.markdown(f"**å¯¾è±¡å•é¡Œ**: {imp.targets_issue}")
                
                # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«çš„ãªæ”¹å–„ç‚¹ã‚’å¼·èª¿
                st.info("ğŸ‘ï¸ ã“ã®æ”¹å–„ã¯è¦–è¦šçš„ãªåŠ¹æœãŒæœŸå¾…ã§ãã¾ã™")

    # === ç”Ÿãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰ ===
    with st.expander("ğŸ“Š è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆé–‹ç™ºè€…å‘ã‘ï¼‰", expanded=False):
        st.json(resp)

    # === ãƒ­ã‚°ã®ä¿å­˜ ===
    run_logger.add_step("display_results", "success", detail={
        "issues_count": len(issues),
        "improvements_count": len(improvements),
    })
    
    st.success(f"âœ… åˆ†æãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ: `{run_dir}`")
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    st.markdown("---")
    st.subheader("ğŸ“¦ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    # JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    import json
    result_json = json.dumps(resp, ensure_ascii=False, indent=2)
    st.download_button(
        label="ğŸ“„ JSONå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=result_json,
        file_name=f"lp_analysis_{genre}.json",
        mime="application/json"
    )

# ==== ãƒ•ãƒƒã‚¿ãƒ¼ ====
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>ğŸ¨ LP AI Analyzer - ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥è¦–è¦šæ”¹å–„ææ¡ˆ</p>
    <p>SaaS / D2C / æ•™è‚² / æ¡ç”¨ / ã‚¢ãƒ—ãƒª ã®å„ã‚¸ãƒ£ãƒ³ãƒ«ã«æœ€é©åŒ–</p>
</div>
""", unsafe_allow_html=True)

